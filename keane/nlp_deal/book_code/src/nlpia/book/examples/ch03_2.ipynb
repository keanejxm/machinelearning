{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'faster', 'harry', 'got', 'to', 'the', 'store', ',', 'the', 'faster', 'harry', ',', 'the', 'faster', ',', 'would', 'get', 'home', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "sentence = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "token_sequence = tokenizer.tokenize(sentence.lower())\n",
    "print(token_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 4, 'faster': 3, ',': 3, 'harry': 2, 'got': 1, 'to': 1, 'store': 1, 'would': 1, 'get': 1, 'home': 1, '.': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "bag_of_words = Counter(token_sequence)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4), ('faster', 3), (',', 3), ('harry', 2), ('got', 1), ('to', 1), ('store', 1), ('would', 1), ('get', 1), ('home', 1), ('.', 1)]\n"
     ]
    }
   ],
   "source": [
    "word_list = bag_of_words.most_common()  # Passing an integer as an argument will give you that many from the top of the list\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "times_harry_appears = bag_of_words['harry']\n",
    "total_words = len(word_list) # The number of tokens from our original source.\n",
    "tf = times_harry_appears/total_words\n",
    "\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kite_text = \"A kite is traditionally a tethered heavier-than-air craft with wing surfaces that react against the air to create lift and drag. A kite consists of wings, tethers, and anchors. Kites often have a bridle to guide the face of the kite at the correct angle so the wind can lift it. A kite's wing also may be so designed so a bridle is not needed; when kiting a sailplane for launch, the tether meets the wing at a single point. A kite may have fixed or moving anchors. Untraditionally in technical kiting, a kite consists of tether-set-coupled wing sets; even in technical kiting, though, a wing in the system is still often called the kite. The lift that sustains the kite in flight is generated when air flows around the kite's surface, producing low pressure above and high pressure below the wings. The interaction with the wind also generates horizontal drag along the direction of the wind. The resultant force vector from the lift and drag force components is opposed by the tension of one or more of the lines or tethers to which the kite is attached. The anchor point of the kite line may be static or moving (e.g., the towing of a kite by a running person, boat, free-falling anchors as in paragliders and fugitive parakites or vehicle). The same principles of fluid flow apply in liquids and kites are also used under water. A hybrid tethered craft comprising both a lighter-than-air balloon as well as a kite lifting surface is called a kytoon. Kites have a long and varied history and many different types are flown individually and at festivals worldwide. Kites may be flown for recreation, art or other practical uses. Sport kites can be flown in aerial ballet, sometimes as part of a competition. Power kites are multi-line steerable kites designed to generate large forces which can be used to power activities such as kite surfing, kite landboarding, kite fishing, kite buggying and a new trend snow kiting. Even Man-lifting kites have been made.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 26, 'a': 20, 'kite': 16, ',': 15, 'and': 10, 'of': 10, 'kites': 8, 'is': 7, 'in': 7, 'or': 6, 'wing': 5, 'to': 5, 'be': 5, 'as': 5, 'lift': 4, 'have': 4, 'may': 4, 'at': 3, 'so': 3, 'can': 3, 'also': 3, 'kiting': 3, 'are': 3, 'flown': 3, 'tethered': 2, 'craft': 2, 'with': 2, 'that': 2, 'air': 2, 'consists': 2, 'tethers': 2, 'anchors.': 2, 'often': 2, 'bridle': 2, 'wind': 2, \"'s\": 2, 'designed': 2, ';': 2, 'when': 2, 'for': 2, 'moving': 2, 'technical': 2, 'even': 2, 'called': 2, 'surface': 2, 'pressure': 2, 'drag': 2, 'force': 2, 'by': 2, 'which': 2, '.': 2, 'used': 2, 'power': 2, 'traditionally': 1, 'heavier-than-air': 1, 'surfaces': 1, 'react': 1, 'against': 1, 'create': 1, 'drag.': 1, 'wings': 1, 'guide': 1, 'face': 1, 'correct': 1, 'angle': 1, 'it.': 1, 'not': 1, 'needed': 1, 'sailplane': 1, 'launch': 1, 'tether': 1, 'meets': 1, 'single': 1, 'point.': 1, 'fixed': 1, 'untraditionally': 1, 'tether-set-coupled': 1, 'sets': 1, 'though': 1, 'system': 1, 'still': 1, 'kite.': 1, 'sustains': 1, 'flight': 1, 'generated': 1, 'flows': 1, 'around': 1, 'producing': 1, 'low': 1, 'above': 1, 'high': 1, 'below': 1, 'wings.': 1, 'interaction': 1, 'generates': 1, 'horizontal': 1, 'along': 1, 'direction': 1, 'wind.': 1, 'resultant': 1, 'vector': 1, 'from': 1, 'components': 1, 'opposed': 1, 'tension': 1, 'one': 1, 'more': 1, 'lines': 1, 'attached.': 1, 'anchor': 1, 'point': 1, 'line': 1, 'static': 1, '(': 1, 'e.g.': 1, 'towing': 1, 'running': 1, 'person': 1, 'boat': 1, 'free-falling': 1, 'anchors': 1, 'paragliders': 1, 'fugitive': 1, 'parakites': 1, 'vehicle': 1, ')': 1, 'same': 1, 'principles': 1, 'fluid': 1, 'flow': 1, 'apply': 1, 'liquids': 1, 'under': 1, 'water.': 1, 'hybrid': 1, 'comprising': 1, 'both': 1, 'lighter-than-air': 1, 'balloon': 1, 'well': 1, 'lifting': 1, 'kytoon.': 1, 'long': 1, 'varied': 1, 'history': 1, 'many': 1, 'different': 1, 'types': 1, 'individually': 1, 'festivals': 1, 'worldwide.': 1, 'recreation': 1, 'art': 1, 'other': 1, 'practical': 1, 'uses.': 1, 'sport': 1, 'aerial': 1, 'ballet': 1, 'sometimes': 1, 'part': 1, 'competition.': 1, 'multi-line': 1, 'steerable': 1, 'generate': 1, 'large': 1, 'forces': 1, 'activities': 1, 'such': 1, 'surfing': 1, 'landboarding': 1, 'fishing': 1, 'buggying': 1, 'new': 1, 'trend': 1, 'snow': 1, 'kiting.': 1, 'man-lifting': 1, 'been': 1, 'made': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# kite_text = \"A kite is traditionally ...\"  # Step left to user, so we aren't repeating ourselves\n",
    "tokens = tokenizer.tokenize(kite_text.lower())\n",
    "token_sequence = Counter(tokens)\n",
    "print(token_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/uglyboxer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Counter({'kite': 16, ',': 15, 'kites': 8, 'wing': 5, 'lift': 4, 'may': 4, 'also': 3, 'kiting': 3, 'flown': 3, 'tethered': 2, 'craft': 2, 'air': 2, 'consists': 2, 'tethers': 2, 'anchors.': 2, 'often': 2, 'bridle': 2, 'wind': 2, \"'s\": 2, 'designed': 2, ';': 2, 'moving': 2, 'technical': 2, 'even': 2, 'called': 2, 'surface': 2, 'pressure': 2, 'drag': 2, 'force': 2, '.': 2, 'used': 2, 'power': 2, 'traditionally': 1, 'heavier-than-air': 1, 'surfaces': 1, 'react': 1, 'create': 1, 'drag.': 1, 'wings': 1, 'guide': 1, 'face': 1, 'correct': 1, 'angle': 1, 'it.': 1, 'needed': 1, 'sailplane': 1, 'launch': 1, 'tether': 1, 'meets': 1, 'single': 1, 'point.': 1, 'fixed': 1, 'untraditionally': 1, 'tether-set-coupled': 1, 'sets': 1, 'though': 1, 'system': 1, 'still': 1, 'kite.': 1, 'sustains': 1, 'flight': 1, 'generated': 1, 'flows': 1, 'around': 1, 'producing': 1, 'low': 1, 'high': 1, 'wings.': 1, 'interaction': 1, 'generates': 1, 'horizontal': 1, 'along': 1, 'direction': 1, 'wind.': 1, 'resultant': 1, 'vector': 1, 'components': 1, 'opposed': 1, 'tension': 1, 'one': 1, 'lines': 1, 'attached.': 1, 'anchor': 1, 'point': 1, 'line': 1, 'static': 1, '(': 1, 'e.g.': 1, 'towing': 1, 'running': 1, 'person': 1, 'boat': 1, 'free-falling': 1, 'anchors': 1, 'paragliders': 1, 'fugitive': 1, 'parakites': 1, 'vehicle': 1, ')': 1, 'principles': 1, 'fluid': 1, 'flow': 1, 'apply': 1, 'liquids': 1, 'water.': 1, 'hybrid': 1, 'comprising': 1, 'lighter-than-air': 1, 'balloon': 1, 'well': 1, 'lifting': 1, 'kytoon.': 1, 'long': 1, 'varied': 1, 'history': 1, 'many': 1, 'different': 1, 'types': 1, 'individually': 1, 'festivals': 1, 'worldwide.': 1, 'recreation': 1, 'art': 1, 'practical': 1, 'uses.': 1, 'sport': 1, 'aerial': 1, 'ballet': 1, 'sometimes': 1, 'part': 1, 'competition.': 1, 'multi-line': 1, 'steerable': 1, 'generate': 1, 'large': 1, 'forces': 1, 'activities': 1, 'surfing': 1, 'landboarding': 1, 'fishing': 1, 'buggying': 1, 'new': 1, 'trend': 1, 'snow': 1, 'kiting.': 1, 'man-lifting': 1, 'made': 1})\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "tokens = [x for x in tokens if x not in stopwords]\n",
    "kite_count = Counter(tokens)\n",
    "print(kite_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07207207207207207, 0.06756756756756757, 0.036036036036036036, 0.02252252252252252, 0.018018018018018018, 0.018018018018018018, 0.013513513513513514, 0.013513513513513514, 0.013513513513513514, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.009009009009009009, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045, 0.0045045045045045045]\n"
     ]
    }
   ],
   "source": [
    "document_vector = []\n",
    "doc_length = len(tokens)\n",
    "for key, value in kite_count.most_common():\n",
    "    document_vector.append(value / doc_length)\n",
    "\n",
    "print(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_0 = \"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\n",
    "doc_1 = \"Harry is hairy and faster than Jill.\"\n",
    "doc_2 = \"Jill is not as hairy as Harry.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is', 'to', 'the', 'would', 'store', 'hairy', 'as', ',', 'got', 'faster', 'get', '.', 'than', 'jill', 'home', 'harry', 'not', 'and'}\n"
     ]
    }
   ],
   "source": [
    "tokens_0 = tokenizer.tokenize(doc_0.lower())\n",
    "tokens_1 = tokenizer.tokenize(doc_1.lower())\n",
    "tokens_2 = tokenizer.tokenize(doc_2.lower())\n",
    "lexicon = set(tokens_0 + tokens_1 + tokens_2)\n",
    "\n",
    "print(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('is', 0), ('to', 0), ('the', 0), ('would', 0), ('store', 0), ('hairy', 0), ('as', 0), (',', 0), ('got', 0), ('faster', 0), ('get', 0), ('.', 0), ('than', 0), ('jill', 0), ('home', 0), ('harry', 0), ('not', 0), ('and', 0)])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "vector_template = OrderedDict((token, 0) for token in lexicon)\n",
    "print(vector_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "document_vectors = []\n",
    "for doc in [doc_0, doc_1, doc_2]:\n",
    "\n",
    "    vec = copy.copy(vector_template)  # So we are dealing with new objects, not multiple references to the same object\n",
    "\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "\n",
    "    for key, value in token_counts.items():\n",
    "        vec[key] = value / len(lexicon)\n",
    "    document_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Since our vectors are dictionaries, lets convert them to lists for easier mathing.\n",
    "    \"\"\"\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "    \n",
    "    dot_prod = 0\n",
    "    for i, v in enumerate(vec1):\n",
    "        dot_prod += v * vec2[i]\n",
    "        \n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    \n",
    "    return dot_prod / (mag_1 * mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161192\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "print(len(brown.words()))  # words is a builtin method of the nltk corpus object that gives a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 69971), ('of', 36412), ('and', 28853), ('to', 26158), ('a', 23195), ('in', 21337), ('that', 10594), ('is', 10109), ('was', 9815), ('he', 9548), ('for', 9489), ('it', 8760), ('with', 7289), ('as', 7253), ('his', 6996), ('on', 6741), ('be', 6377), ('at', 5372), ('by', 5306), ('i', 5164)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "puncs = [',', '.', '--', '-', '!', '?', ':', ';', '``', \"''\", '(', ')', '[', ']']\n",
    "word_list = [x.lower() for x in brown.words() if x not in puncs]\n",
    "token_counts = Counter(word_list)\n",
    "print(token_counts.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_text = 'Kites were invented in China, where materials ideal for kite building were readily available: silk fabric for sail material; fine, high-tensile-strength silk for flying line; and resilient bamboo for a strong, lightweight framework. The kite has been claimed as the invention of the 5th-century BC Chinese philosophers Mozi (also Mo Di) and Lu Ban (also Gongshu Ban). By 549 AD paper kites were certainly being flown, as it was recorded that in that year a paper kite was used as a message for a rescue mission. Ancient and medieval Chinese sources describe kites being used for measuring distances, testing the wind, lifting men, signaling, and communication for military operations. The earliest known Chinese kites were flat (not bowed) and often rectangular. Later, tailless kites incorporated a stabilizing bowline. Kites were decorated with mythological motifs and legendary figures; some were fitted with strings and whistles to make musical sounds while flying. From China, kites were introduced to Cambodia, Thailand, India, Japan, Korea and the western world. After its introduction into India, the kite further evolved into the fighter kite, known as the patang in India, where thousands are flown every year on festivals such as Makar Sankranti. Kites were known throughout Polynesia, as far as New Zealand, with the assumption being that the knowledge diffused from China along with the people. Anthropomorphic kites made from cloth and wood were used in religious ceremonies to send prayers to the gods. Polynesian kite traditions are used by anthropologists get an idea of early \"primitive\" Asian traditions that are believed to have at one time existed in Asia.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intro_text = \"A kite is traditionally ...\"  # Step left to user, as above\n",
    "intro_text = kite_text.lower()\n",
    "intro_tokens = tokenizer.tokenize(intro_text)\n",
    "# history_text = \"Kites were invented in China, ...\"  # Also as above\n",
    "history_text = history_text.lower()\n",
    "history_tokens = tokenizer.tokenize(history_text)\n",
    "intro_total = len(intro_tokens)\n",
    "history_total = len(history_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency of \"kite\" in intro is: 0.0440771349862259\n",
      "Term Frequency of \"kite\" in history is: 0.020202020202020204\n"
     ]
    }
   ],
   "source": [
    "intro_tf = {}\n",
    "history_tf = {}\n",
    "intro_counts = Counter(intro_tokens)\n",
    "intro_tf['kite'] = intro_counts['kite'] / intro_total\n",
    "history_counts = Counter(history_tokens)\n",
    "history_tf['kite'] = history_counts['kite'] / history_total\n",
    "print('Term Frequency of \"kite\" in intro is: {}'.format(intro_tf['kite']))\n",
    "print('Term Frequency of \"kite\" in history is: {}'.format(history_tf['kite']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency of \"and\" in intro is: 0.027548209366391185\n",
      "Term Frequency of \"and\" in history is: 0.030303030303030304\n"
     ]
    }
   ],
   "source": [
    "intro_tf['and'] = intro_counts['and'] / intro_total\n",
    "history_tf['and'] = history_counts['and'] / history_total\n",
    "print('Term Frequency of \"and\" in intro is: {}'.format(intro_tf['and']))\n",
    "print('Term Frequency of \"and\" in history is: {}'.format(history_tf['and']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_docs_containing_and = 0\n",
    "for doc in [intro_tokens, history_tokens]:\n",
    "    if 'and' in doc:\n",
    "        num_docs_containing_and += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_docs_containing_kite = 0\n",
    "for doc in [intro_tokens, history_tokens]:\n",
    "    if 'kite' in doc:\n",
    "        num_docs_containing_kite += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_docs_containing_china = 0\n",
    "for doc in [intro_tokens, history_tokens]:\n",
    "    if 'china' in doc:\n",
    "        num_docs_containing_china += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intro_tf['china'] = intro_counts['china'] / intro_total\n",
    "history_tf['china'] = history_counts['china'] / history_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_docs = 2\n",
    "intro_idf = {}\n",
    "history_idf = {}\n",
    "intro_idf['and'] = num_docs / num_docs_containing_and \n",
    "history_idf['and'] = num_docs / num_docs_containing_and \n",
    "intro_idf['kite'] = num_docs / num_docs_containing_kite \n",
    "history_idf['kite'] = num_docs / num_docs_containing_kite \n",
    "intro_idf['china'] = num_docs / num_docs_containing_china \n",
    "history_idf['china'] = num_docs / num_docs_containing_china "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intro_tfidf = {}\n",
    "\n",
    "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']\n",
    "intro_tfidf['kite'] = intro_tf['kite'] * intro_idf['kite']\n",
    "intro_tfidf['china'] = intro_tf['china'] * intro_idf['china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_tfidf = {}\n",
    "\n",
    "history_tfidf['and'] = history_tf['and'] * history_idf['and']\n",
    "history_tfidf['kite'] = history_tf['kite'] * history_idf['kite']\n",
    "history_tfidf['china'] = history_tf['china'] * history_idf['china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_tfidf_vectors = []\n",
    "documents = [doc_0, doc_1, doc_2]\n",
    "for doc in documents:\n",
    "\n",
    "    vec = copy.copy(vector_template)  # So we are dealing with new objects, not multiple references to the same object\n",
    "\n",
    "    tokens = tokenizer.tokenize(doc.lower())\n",
    "    token_counts = Counter(tokens)\n",
    "\n",
    "    for key, value in token_counts.items():\n",
    "        docs_containing_key = 0\n",
    "        for _doc in documents:\n",
    "          if key in _doc:\n",
    "            docs_containing_key += 1\n",
    "        tf = value / len(lexicon)\n",
    "        if docs_containing_key:\n",
    "            idf = len(documents) / docs_containing_key\n",
    "        else:\n",
    "            idf = 0\n",
    "        vec[key] = tf * idf \n",
    "    document_tfidf_vectors.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5235048549676835\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "query = \"How long does it take to get to the store?\"\n",
    "query_vec = copy.copy(vector_template) \n",
    "\n",
    "query_vec = copy.copy(vector_template)  # So we are dealing with new objects, not multiple references to the same object\n",
    "\n",
    "tokens = tokenizer.tokenize(query.lower())\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "for key, value in token_counts.items():\n",
    "    docs_containing_key = 0\n",
    "    for _doc in documents:\n",
    "      if key in _doc.lower():\n",
    "        docs_containing_key += 1\n",
    "    if docs_containing_key == 0:  # We didn't find that token in the lexicon go to next key\n",
    "        continue\n",
    "    tf = value / len(tokens)\n",
    "    idf = len(documents) / docs_containing_key \n",
    "    query_vec[key] = tf * idf \n",
    "\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[0]))\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[1]))\n",
    "print(cosine_sim(query_vec, document_tfidf_vectors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.42662402  0.18698644  0.18698644  0.\n",
      "   0.22087441  0.18698644  0.          0.          0.          0.18698644\n",
      "   0.          0.74794576  0.18698644  0.18698644]\n",
      " [ 0.46312056  0.          0.35221512  0.          0.          0.35221512\n",
      "   0.27352646  0.          0.35221512  0.35221512  0.          0.\n",
      "   0.46312056  0.          0.          0.        ]\n",
      " [ 0.          0.75143242  0.          0.          0.          0.28574186\n",
      "   0.22190405  0.          0.28574186  0.28574186  0.37571621  0.          0.\n",
      "   0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [doc_0, doc_1, doc_2]\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "model = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(model.todense())  # The model becomes a sparse numpy matrix, as in a large corpus there would be mostly zeros to deal with.  todense() brings it back to a regular numpy matrix for our viewing pleasure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
